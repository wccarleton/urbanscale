{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Documentation Building\n",
    "This notebook was used to create content from the repo folders (scripts and analytical outputs) to be used in compiling a comprehensive supplementary document. The document should summarize the key analytical and diagnostic results of the various analyses, extending and supporting the presentation of the main paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "The following libraries were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the R Script\n",
    "Here, we are trying to summarize the structure of the R script. The script itself is already extensively documented with clear section headings. So, we will exctract on the doc strings and use that to build the framework for a markdown document section (part of the supplementary document) that summarizes the analytical workflow in the script providing clear headers, context, inputs, and outputs for the main script sections.\n",
    "\n",
    "Extract analysis pipline from doc strings in the R script file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction successful! Comments saved to Src/code_docs_outline.txt\n"
     ]
    }
   ],
   "source": [
    "# Python script to extract comments (lines starting with '#') from an R script\n",
    "def extract_comments(input_path, output_path):\n",
    "    try:\n",
    "        with open(input_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
    "            for line in infile:\n",
    "                stripped_line = line.lstrip()\n",
    "                if stripped_line.startswith(\"#\"):  # Identify comment lines\n",
    "                    outfile.write(line)  # Write comment to output file\n",
    "        print(f\"Extraction successful! Comments saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Specify the input R script and output text file\n",
    "input_path = \"Src/urban_wealth_scale.R\"\n",
    "output_path = \"Src/code_docs_outline.txt\"\n",
    "\n",
    "# Run the extraction\n",
    "extract_comments(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output File Table\n",
    "To make it easier for reviewers and readers to navigate the project repo, we will construct a summary table of the analytical outputs produced by the R script. There are around 190 output files, comprising both numerical and plot outputs. Here we will just grab the filenames from the Output folder and write them to a csv for further automated and manual processing.\n",
    "\n",
    "Get all the output filenames for processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filenames from 'Output/' written to 'Output/output_filenames.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define the directory and output CSV filename\n",
    "output_folder = \"../Output/\"\n",
    "csv_filename = \"output_filenames.csv\"\n",
    "\n",
    "# Get all filenames in the Output folder\n",
    "file_list = os.listdir(output_folder)\n",
    "\n",
    "# Write filenames to a CSV file\n",
    "with open(csv_filename, mode='w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header\n",
    "    csv_writer.writerow([\"Filename\"])\n",
    "    # Write each filename as a row\n",
    "    for filename in file_list:\n",
    "        csv_writer.writerow([filename])\n",
    "\n",
    "print(f\"Filenames from '{output_folder}' written to '{csv_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to take in the csv of filenames, add context based on the filename conventions used for the analysis, sort the files, and create a markdown table based on the sorted filenames with metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file containing the filenames\n",
    "file_path = \"output_table_file_map.csv\"  # Update this path to your actual file location\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the desired order for 'Type' and 'Analysis' columns\n",
    "type_order = ['Summary', 'Plot', 'Numeric']\n",
    "analysis_order = ['Main', 'Supplemental']\n",
    "context_order = ['Summary', 'Model Diagnostic', 'MCMC Diagnostic']\n",
    "\n",
    "# Replace NaNs in 'Type' column with empty string to process them\n",
    "df['Type'] = df['Type'].fillna('')\n",
    "\n",
    "# Assign 'Numeric' type to any rows with filenames ending in .csv\n",
    "df.loc[df['Filename'].str.endswith('.csv'), 'Type'] = 'Numeric'\n",
    "\n",
    "# Add the 'Context' column and initialize with an empty string\n",
    "df['Context'] = ''\n",
    "\n",
    "# Fill 'Context' column based on rules\n",
    "df.loc[(df['Model'].str.contains('all', case=False, na=False)) | \n",
    "       (df['Filename'].str.contains('summary', case=False, na=False)), 'Context'] = 'Summary'\n",
    "\n",
    "df.loc[df['Filename'].str.contains('tplots|geweke|grrhat', case=False, na=False), 'Context'] = 'MCMC Diagnostic'\n",
    "\n",
    "df.loc[df['Filename'].str.contains('lppd|loo|resid|outlier', case=False, na=False), 'Context'] = 'Model Diagnostic'\n",
    "\n",
    "# Convert the columns to categorical with the specified order\n",
    "df['Analysis'] = pd.Categorical(df['Analysis'], categories=analysis_order, ordered=True)\n",
    "df['Type'] = pd.Categorical(df['Type'], categories=type_order, ordered=True)\n",
    "df['Context'] = pd.Categorical(df['Context'], categories=context_order, ordered=True)\n",
    "\n",
    "# Sort the dataframe by 'Type' and then by 'Analysis'\n",
    "sorted_df = df.sort_values(by=['Analysis', 'Type', 'Context'])\n",
    "\n",
    "# Save the sorted dataframe back to a CSV (or modify this to write Markdown if needed)\n",
    "output_csv_path = \"sorted_filenames_metadata.csv\"\n",
    "\n",
    "if os.path.exists(output_csv_path):\n",
    "    os.remove(output_csv_path)\n",
    "\n",
    "sorted_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Generate the markdown table\n",
    "output_path = \"sorted_filenames_metadata.md\"\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    os.remove(output_path)\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    # Write the table header\n",
    "    f.write(\"| Analysis | Type | Context | Model | Script Section | Filename |\\n\")\n",
    "    f.write(\"|----------|------|---------|-------|----------------|----------|\\n\")\n",
    "    \n",
    "    # Write each row as a markdown table row\n",
    "    for _, row in sorted_df.iterrows():\n",
    "        f.write(f\"| {row['Analysis']} | {row['Type']} | {row['Context']} | {row['Model']} | {row['Script Section']} | {row['Filename']} |\\n\")\n",
    "\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sorting and adding context/metadata, the filenames are stored in `sorted_filenames_metadata.csv` which is then used to build a series of markdown tables decribing all of the files in the Output folder divided into main, supplemental, numeric, and plot tables (turned out to be necessary in order to easily display the content in a simple markdown document without having to tweak the underlying LaTex)---analytical products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-sorted CSV file\n",
    "file_path = \"sorted_filenames_metadata.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def save_grouped_table(df_subset, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        # Write the table header\n",
    "        f.write(\"| Context | Script Section | Filename |\\n\")\n",
    "        f.write(\"|---------|----------------|----------|\\n\")\n",
    "\n",
    "        # Initialize tracking for the current group\n",
    "        current_group = None\n",
    "\n",
    "        for _, row in df_subset.iterrows():\n",
    "            # Extract the group name (substring before the first `_`)\n",
    "            split_filename = row['Filename'].split('_', 1)\n",
    "            group_name = split_filename[0]\n",
    "            \n",
    "            # Check if a new group starts\n",
    "            if group_name != current_group:\n",
    "                # Write a group header row with the trailing underscore and ellipsis\n",
    "                f.write(f\"| | | **{group_name}_...** |\\n\")  # Empty Context and Script Section\n",
    "                current_group = group_name\n",
    "\n",
    "            # Write the filename row, removing the group prefix\n",
    "            cleaned_filename = split_filename[1] if len(split_filename) > 1 else split_filename[0]\n",
    "            f.write(f\"| {row['Context']} | {row['Script Section']} | {cleaned_filename} |\\n\")\n",
    "\n",
    "# Example usage with subsets of the DataFrame\n",
    "save_grouped_table(main_plot, \"grouped_main_plot.md\")\n",
    "save_grouped_table(main_numeric, \"grouped_main_numeric.md\")\n",
    "save_grouped_table(supplemental_plot, \"grouped_supplemental_plot.md\")\n",
    "save_grouped_table(supplemental_numeric, \"grouped_supplemental_numeric.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress the PNGs so that the final supplement.pdf isn't so big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed ..\\Output\\geweke_histogram.png to compressed_images\\geweke_histogram.png\n",
      "Compressed ..\\Output\\grrhat_histogram.png to compressed_images\\grrhat_histogram.png\n",
      "Compressed ..\\Output\\pa_gini_results.png to compressed_images\\pa_gini_results.png\n",
      "Compressed ..\\Output\\point_scatters.png to compressed_images\\point_scatters.png\n",
      "Compressed ..\\Output\\point_scatters_linear.png to compressed_images\\point_scatters_linear.png\n",
      "Compressed ..\\Output\\point_scatters_linear_log.png to compressed_images\\point_scatters_linear_log.png\n",
      "Compressed ..\\Output\\resid_allmonuments.png to compressed_images\\resid_allmonuments.png\n",
      "Compressed ..\\Output\\resid_allmonuments_linlog.png to compressed_images\\resid_allmonuments_linlog.png\n",
      "Compressed ..\\Output\\resid_allwalls.png to compressed_images\\resid_allwalls.png\n",
      "Compressed ..\\Output\\resid_allwalls_linlog.png to compressed_images\\resid_allwalls_linlog.png\n",
      "Compressed ..\\Output\\resid_epigraphy.png to compressed_images\\resid_epigraphy.png\n",
      "Compressed ..\\Output\\resid_epigraphy_linlog.png to compressed_images\\resid_epigraphy_linlog.png\n",
      "Compressed ..\\Output\\resid_filtmonuments.png to compressed_images\\resid_filtmonuments.png\n",
      "Compressed ..\\Output\\resid_filtmonuments_loglin.png to compressed_images\\resid_filtmonuments_loglin.png\n",
      "Compressed ..\\Output\\resid_hnwi.png to compressed_images\\resid_hnwi.png\n",
      "Compressed ..\\Output\\resid_hnwi_linlog.png to compressed_images\\resid_hnwi_linlog.png\n",
      "Compressed ..\\Output\\resid_tallbuildings.png to compressed_images\\resid_tallbuildings.png\n",
      "Compressed ..\\Output\\resid_tallbuildings_linlog.png to compressed_images\\resid_tallbuildings_linlog.png\n",
      "Compressed ..\\Output\\scaling_posteriors.png to compressed_images\\scaling_posteriors.png\n",
      "Compressed ..\\Output\\tplots_allmonuments.png to compressed_images\\tplots_allmonuments.png\n",
      "Compressed ..\\Output\\tplots_allmonuments_linlog.png to compressed_images\\tplots_allmonuments_linlog.png\n",
      "Compressed ..\\Output\\tplots_allmonuments_linlog_provinces.png to compressed_images\\tplots_allmonuments_linlog_provinces.png\n",
      "Compressed ..\\Output\\tplots_allmonuments_nozero.png to compressed_images\\tplots_allmonuments_nozero.png\n",
      "Compressed ..\\Output\\tplots_allmonuments_nozero_provinces.png to compressed_images\\tplots_allmonuments_nozero_provinces.png\n",
      "Compressed ..\\Output\\tplots_allmonuments_provinces.png to compressed_images\\tplots_allmonuments_provinces.png\n",
      "Compressed ..\\Output\\tplots_allmonuments_sup.png to compressed_images\\tplots_allmonuments_sup.png\n",
      "Compressed ..\\Output\\tplots_allmonuments_sup_provinces.png to compressed_images\\tplots_allmonuments_sup_provinces.png\n",
      "Compressed ..\\Output\\tplots_allwalls.png to compressed_images\\tplots_allwalls.png\n",
      "Compressed ..\\Output\\tplots_allwalls_linlog.png to compressed_images\\tplots_allwalls_linlog.png\n",
      "Compressed ..\\Output\\tplots_allwalls_linlog_provinces.png to compressed_images\\tplots_allwalls_linlog_provinces.png\n",
      "Compressed ..\\Output\\tplots_allwalls_nozero.png to compressed_images\\tplots_allwalls_nozero.png\n",
      "Compressed ..\\Output\\tplots_allwalls_nozero_provinces.png to compressed_images\\tplots_allwalls_nozero_provinces.png\n",
      "Compressed ..\\Output\\tplots_allwalls_provinces.png to compressed_images\\tplots_allwalls_provinces.png\n",
      "Compressed ..\\Output\\tplots_epigraphy.png to compressed_images\\tplots_epigraphy.png\n",
      "Compressed ..\\Output\\tplots_epigraphy_linlog.png to compressed_images\\tplots_epigraphy_linlog.png\n",
      "Compressed ..\\Output\\tplots_epigraphy_linlog_provinces.png to compressed_images\\tplots_epigraphy_linlog_provinces.png\n",
      "Compressed ..\\Output\\tplots_epigraphy_nozero.png to compressed_images\\tplots_epigraphy_nozero.png\n",
      "Compressed ..\\Output\\tplots_epigraphy_nozero_provinces.png to compressed_images\\tplots_epigraphy_nozero_provinces.png\n",
      "Compressed ..\\Output\\tplots_epigraphy_provinces.png to compressed_images\\tplots_epigraphy_provinces.png\n",
      "Compressed ..\\Output\\tplots_filtmonuments.png to compressed_images\\tplots_filtmonuments.png\n",
      "Compressed ..\\Output\\tplots_filtmonuments_loglin.png to compressed_images\\tplots_filtmonuments_loglin.png\n",
      "Compressed ..\\Output\\tplots_filtmonuments_loglin_provinces.png to compressed_images\\tplots_filtmonuments_loglin_provinces.png\n",
      "Compressed ..\\Output\\tplots_filtmonuments_nozero.png to compressed_images\\tplots_filtmonuments_nozero.png\n",
      "Compressed ..\\Output\\tplots_filtmonuments_nozero_provinces.png to compressed_images\\tplots_filtmonuments_nozero_provinces.png\n",
      "Compressed ..\\Output\\tplots_filtmonuments_provinces.png to compressed_images\\tplots_filtmonuments_provinces.png\n",
      "Compressed ..\\Output\\tplots_hnwi.png to compressed_images\\tplots_hnwi.png\n",
      "Compressed ..\\Output\\tplots_hnwi_linlog.png to compressed_images\\tplots_hnwi_linlog.png\n",
      "Compressed ..\\Output\\tplots_hnwi_sup.png to compressed_images\\tplots_hnwi_sup.png\n",
      "Compressed ..\\Output\\tplots_tallbuildings.png to compressed_images\\tplots_tallbuildings.png\n",
      "Compressed ..\\Output\\tplots_tallbuildings_linlog.png to compressed_images\\tplots_tallbuildings_linlog.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def compress_png_pillow(input_dir, output_dir, resize_factor=0.5, quality=85):\n",
    "    \"\"\"\n",
    "    Compress PNG files using Pillow by resizing and adjusting quality.\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "    for png_file in input_dir.glob(\"*.png\"):\n",
    "        with Image.open(png_file) as img:  # Ensure file is properly closed after processing\n",
    "            # Resize image\n",
    "            new_dimensions = (\n",
    "                int(img.width * resize_factor),\n",
    "                int(img.height * resize_factor)\n",
    "            )\n",
    "            img_resized = img.resize(new_dimensions, Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Save compressed image\n",
    "            compressed_file = output_dir / png_file.name\n",
    "            img_resized.save(compressed_file, optimize=True, quality=quality)\n",
    "            print(f\"Compressed {png_file} to {compressed_file}\")\n",
    "\n",
    "# Run the function\n",
    "compress_png_pillow(\"../Output\", \"compressed_images\", 0.5, 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Plots\n",
    "We now create a traceplot section for the supplement by adding the traceplot PNG files to a separate markdown document that will be included in the main supplement.\n",
    "\n",
    "Everything that follows happens within the Suppelement subfolder of the primary project Repo. Create a markdown file containing all the trace plots that can later be included in the main supplement file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown section for tplots created at: tplots_section.md\n"
     ]
    }
   ],
   "source": [
    "# Read the metadata table\n",
    "metadata_path = \"sorted_filenames_metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Filter for `tplots_...png` files and maintain order from metadata\n",
    "tplots_files = metadata[metadata['Filename'].str.contains('tplots_') & metadata['Filename'].str.endswith('.png')]\n",
    "\n",
    "# Generate the Markdown content\n",
    "md_content = \"# Trace Plots\\n\\n\"\n",
    "md_content += \"This section contains the trace plots (`tplots_...png`) for the MCMC diagnostics.\\n\\n\"\n",
    "\n",
    "for _, row in tplots_files.iterrows():\n",
    "    filename = row['Filename']\n",
    "    relative_path = f\"compressed_images/{filename}\"\n",
    "    md_content += f\"### {filename}\\n\"\n",
    "    md_content += f\"![{filename}]({relative_path})\\n\\n\"\n",
    "\n",
    "# Write the Markdown content to a new file\n",
    "output_md_path = \"tplots_section.md\"\n",
    "\n",
    "if os.path.exists(output_md_path):\n",
    "    os.remove(output_md_path)\n",
    "\n",
    "with open(output_md_path, \"w\") as md_file:\n",
    "    md_file.write(md_content)\n",
    "\n",
    "print(f\"Markdown section for tplots created at: {output_md_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Parameter Posteriors\n",
    "The anlaysis produed hundreds of parameter posterior estimates across the various models and supplemental anlayses. We summarize those here with another markdown table generated by taking in the posterior summaries produced by the R script (as CSVs) and formatting the data into a markdown table.\n",
    "\n",
    "Create markdown summary table of consolidated model posterior summaries for key scaling variables, which will also be included in the main supplement file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown section written to: consolidated_post_summary.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
      "C:\\Users\\carleton\\AppData\\Local\\Temp\\ipykernel_5804\\104452265.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory containing the \"post_summary...\" files\n",
    "output_dir = \"../Output\"\n",
    "markdown_file = \"consolidated_post_summary.md\"\n",
    "\n",
    "# Get all the \"post_summary...\" files\n",
    "post_summary_files = [\n",
    "    f for f in os.listdir(output_dir) if f.startswith(\"post_summary\") and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "# Prepare a consolidated DataFrame\n",
    "consolidated_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each file and extract the relevant rows\n",
    "for file in post_summary_files:\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df.rename(columns={df.columns[0]: \"param\"}, inplace=True)\n",
    "\n",
    "    # Extract the relevant rows\n",
    "    filtered_df = df[df['param'].isin(['b0', 'b1', 'intercept', 'scaling'])]\n",
    "    \n",
    "    # Add a new column for the model/analysis (taken from the file name)\n",
    "    filtered_df['model'] = file.replace(\"post_summary_\", \"\").replace(\".csv\", \"\")\n",
    "    \n",
    "    # Append to the consolidated DataFrame\n",
    "    consolidated_df = pd.concat([consolidated_df, filtered_df], ignore_index=True)\n",
    "\n",
    "# Rearrange the columns\n",
    "consolidated_df = consolidated_df[['model', 'param', 'lower', 'upper', 'mean', 'stdd']]\n",
    "\n",
    "# Create the markdown table\n",
    "markdown_table = consolidated_df.to_markdown(index=False)\n",
    "\n",
    "# Write the markdown to the file\n",
    "with open(markdown_file, \"w\") as f:\n",
    "    f.write(\"# Consolidated Parameter Summary\\n\\n\")\n",
    "    f.write(markdown_table)\n",
    "\n",
    "print(f\"Markdown section written to: {markdown_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
